{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b12696bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "78055573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pycon_url = \"https://in.pycon.org/cfp/pycon-india-2023/proposals\"\n",
    "resp = requests.get(pycon_url)\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eafb23d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = bs(resp.content, 'html.parser')\n",
    "links = soup.find_all(\"h3\", \"proposal--title\")\n",
    "\n",
    "len(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e213480",
   "metadata": {},
   "source": [
    "talk: 35\n",
    "\n",
    "workshops: 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b390884d",
   "metadata": {},
   "outputs": [],
   "source": [
    "talks = links[:35]\n",
    "workshops = links[35: 42]\n",
    "\n",
    "talk_links = [t.a[\"href\"] for t in talks]\n",
    "workshop_links = [workshop.a[\"href\"] for workshop in workshops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36115efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "PYCON_URL = \"https://in.pycon.org\"\n",
    "\n",
    "def get_proposal_data(link):\n",
    "    resp = requests.get(PYCON_URL+link)\n",
    "    soup = bs(resp.content, 'html.parser')\n",
    "\n",
    "    metadata = {}\n",
    "    meta = soup.find(\"section\", \"col-sm-3 proposal-meta\")\n",
    "    if meta is not None:\n",
    "        for r in meta.find_all(\"tr\"):\n",
    "            k, v = r.find_all('td')\n",
    "            k = k.get_text()[:-1]\n",
    "            v = v.get_text().strip()\n",
    "            metadata[k] = v\n",
    "    title = soup.find(\"h1\", \"proposal-title\")\n",
    "    metadata[\"title\"] = title.get_text().strip()\n",
    "    speaker_info = soup.find(\"p\", \"text-muted\")\n",
    "    metadata[\"speaker\"] = speaker_info.b.get_text().strip()\n",
    "    content = soup.find(\"section\", \"col-sm-8 proposal-writeup\")\n",
    "    \n",
    "    return content.get_text(), metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a1556491",
   "metadata": {},
   "outputs": [],
   "source": [
    "c, m = get_proposal_data(workshop_links[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0100555d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Section': 'Data Science, AI & ML',\n",
       " 'Type': 'Workshops',\n",
       " 'Target Audience': 'Intermediate',\n",
       " 'Last Updated': '14 Sep, 2023',\n",
       " 'title': 'All Them Data Engines: Pandas, Spark, Dask, Polars and more - Data Munging with Python circa 2023.',\n",
       " 'speaker': 'shaurya shaurya3 (~shaurya3)'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfdcfdf",
   "metadata": {},
   "source": [
    "### LlamaIndex nodes\n",
    "Now lets make the llamaIndex nodes from this and the metadata that can be obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9f2e93e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.schema import TextNode\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e67475b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(talk_links+workshop_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d15401aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 42/42 [00:21<00:00,  1.95it/s]\n"
     ]
    }
   ],
   "source": [
    "nodes = []\n",
    "for l in tqdm(talk_links+workshop_links):\n",
    "    c, m = get_proposal_data(l)\n",
    "    t = TextNode(text=c, metadata=m)\n",
    "    nodes.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5fdaa4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "db5ecf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the nodes for later\n",
    "import pickle\n",
    "\n",
    "with open(\"py23nodes.pkl\", \"wb\") as f:\n",
    "    pickle.dump(nodes, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e60f2c",
   "metadata": {},
   "source": [
    "## baseline LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f09b9575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex\n",
    "\n",
    "baseline = VectorStoreIndex(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "232953e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, there is a LlamaIndex workshop mentioned in the context information.\n"
     ]
    }
   ],
   "source": [
    "qe = baseline.as_query_engine()\n",
    "q = \"is there a llamaindex workshop?\"\n",
    "r = qe.query(\"is there a llamaindex workshop?\")\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3729241a",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline.storage_context.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a1fc0164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "from llama_index.evaluation import FaithfulnessEvaluator, RelevancyEvaluator\n",
    "\n",
    "service_context = baseline.service_context\n",
    "faithfulness = FaithfulnessEvaluator(service_context=service_context)\n",
    "relevancy = RelevancyEvaluator(service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6abbf39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach to the same event-loop\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9c2b84f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fail'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result = faithfulness.evaluate_response(response=r)\n",
    "\"Pass\" if eval_result.passing else \"Fail\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ac3974e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='Yes, there is a LlamaIndex workshop mentioned in the context information.', source_nodes=[NodeWithScore(node=TextNode(id_='1e264a40-fe2f-4c0f-954b-32427f471b0a', embedding=None, metadata={'Section': 'Data Science, AI & ML', 'Type': 'Workshops', 'Target Audience': 'Beginner', 'Last Updated': '14 Sep, 2023', 'title': 'Mastering Retrieval Augmented Generation (RAG) with LlamaIndex and LLMs', 'speaker': 'ravi theja (~ravi1)'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='e14d7553deeccb8ea1d62416410198657cc8a709cd7f41f92b81101b1fea34fe', text=\"\\n\\nDescription:\\nLlamaIndex is a toolkit designed to enhance the utility of Large Language Models (LLMs). It provides powerful capabilities to bridge the gap between your custom data and LLMs, thereby enabling the construction of sophisticated, data-driven applications. With LlamaIndex, harnessing the potential of retrieval and generation in language models becomes seamless and efficient.\\nIn this hands-on workshop, we will dive into the intricacies of the Retrieval Augmented Generation (RAG) paradigm, demonstrating how it can be leveraged to build potent systems such as Q&A systems, chatbots, and data agents. A core component of our session will be the exploration of LlamaIndex as an essential bridge between LLMs and your custom data, equipping participants with the knowledge to craft tailored applications efficiently. Here is the outline of the workshop.\\nIntroduction\\n\\nBrief on Large Language Models and LlamaIndex.\\nOverview of the Retrieval Augmented Generation (RAG) paradigm\\n\\nUnderstanding RAG Paradigm\\n\\nDetailed explanation of RAG and its applications\\nHow RAG enhances Large Language Models with custom data\\n\\nMastering Indexing and Querying Techniques\\n\\nPreparing a robust knowledge base using LlamaIndex's data connectors\\nand indexing capabilities\\nUnderstanding the retrieval process for the most relevant context\\ngiven a user query\\nSynthesizing responses using LLMs and LlamaIndex for effective\\nquerying\\nPractical demonstration and hands-on practice of these techniques\\n\\nWorking with Advanced Building Blocks\\n\\nPractical experience with retrievers, node postprocessors, and\\nresponse synthesizers\\nUnderstanding the use of these tools in different applications\\n\\nRouter Engines\\n\\nIntroduction to Router Engines as decision-making systems in\\nLlamaIndex\\nChoosing the right query engine/index based on user’s query\\n\\nEvaluation\\n\\nResponse Synthesis Evaluation.\\nResponse + Context Evaluation.\\nQuestion Generation and Evaluation.\\n\\nExploring Data Agents\\n\\nUnderstanding Data Agents and their role in interacting with data\\nDynamic interaction with external tools using Data Agents\\n\\n\\n\\n\\nPrerequisites:\\n\\nPython and Experience with Large Language Models (LLMs)\\nParticipants should have a fundamental understanding of Python programming and prior experience with Large Language Models such as ChatGPT, which will provide a basic comprehension of LLM workings.\\nAccess to Google Colab\\nOur sessions will be conducted using Google Colab, so please ensure you have access to this platform.\\nOpenAI API Key\\nWe'll be utilizing GPT-based models by default for building applications with LlamaIndex, so having an OpenAI API key will be essential.\\n\\n\\n\\n\\nVideo URL:\\nhttps://www.youtube.com/watch?v=7H7sNDg6j34\\n\\n\\n\\nContent URLs: \\nHere is a version of the slides for the workshop. Notebooks for each section will be updated after the proposal acceptance.\\n\\n\\n\\nSpeaker Info:\\nI am an Open Source Contributor at LlamaIndex and Senior Data Scientist at Glance (Inmobi).\\n\\nContributed different data loaders and evaluation modules to LlamaIndex.\\nBuilt Recommender Systems, NLP, and GenAI applications at Glance. I am part of Glance TV team which is a product built entirely using LLM's and vector DB's. Demo\\nI have published papers at ACL and COLING workshops.\\nI have given talks about LlamaIndex at the Hasgeek GenAI meetup, Fifth Elephant Conference, Analytics Vidhya Data Hack Summit, and different VC firms (Accel, Together, Speciale).\\nPublished blogs and videos on LlamaIndex.\\nRecognised as Top 5 GenAI Experts in India by Analytics Vidhya at Data Hack Summit.\\n\\n\\n\\n\\nSpeaker Links:\\nLinkedin\\nTwitter\\nGithub\\nMedium\\n\\n\\n\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8107037109118423), NodeWithScore(node=TextNode(id_='4c88a110-f1a8-4581-b06a-6934b9009d20', embedding=None, metadata={'Section': 'Data Science, AI & ML', 'Type': 'Workshops', 'Target Audience': 'Intermediate', 'Last Updated': '22 Sep, 2023', 'title': 'Instruction Finetuning: Unlock the Power of Large Language Models', 'speaker': 'Abhijeet Kumar (~abhijeet3922)'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='d2c0184455c59c60675b8ad259179daaedcda143e01a60580fbdf87cbd147519', text='\\n\\nDescription:\\nLarge Language models (LLMs) are powerful tools that can be used for variety of tasks such as question answering, translation, content generation and other natural language understanding tasks. However, there are few challenges currently with open source LLMs trained on massive internet data. Two such reasons are:\\n\\nLLMs may not be accurate for complex tasks.\\nLLMs may not have learnt nuances of specific domain well hence does not hold good for such in-domain tasks.\\n\\nThese issues can be resolved by better aligning LLMs by Instruction Finetuning techniques.\\nWhy does it matter ?\\nMany businesses or captive companies intends to owning their models, and create superior quality models for their domain specific applications without handing their sensitive data over to third parties.\\nAgenda\\nThe workshop will cover the mainly the following sections.\\n1. Prompting LLMs (zero/few shot) \\n2. Few-shot Finetuning LLMs\\n3. Instruction Finetuning of LLMs\\n\\nThe workshop may be designed that includes both a tutorial on implementing Instruction Finetuning techniques and hands-on practice session where participants can apply the same on other tasks.\\nWe will cover these section using HuggingFace and other useful libraries for the above agenda. Participants can use Google Collab to perform all the above tasks. For audience aware of LLMs, the workshop intends to demonstrate \"How to train your own Alpaca or Dolly models using Llama-2 models?\". I will begin by covering the basics of working with LLMs and some of few-shot finetuning techniques. I will then build on this foundation to demonstrate how to train replicable models like Alpaca, Dolly etc. with prompt-response pairs.\\nAudience\\nThis workshop is intended for any developers who are interested in finetuning LLMs for improved accuracy. No prior experience of Finetuning LLMs is required. \\nBasic to Intermediate skillset should be fine.\\nOutcomes\\nBy the end of the workshop, participants will be able to:\\n\\nWorking with recent LLMs\\nFinetune LLM using labelled examples.\\nInstruction Finetuning of LLMs.\\nPractical aspects of applications.\\n\\nMaterials\\nThe workshop will provide participants with all the materials they need to complete the exercises. These materials will include a workshop notebooks, datasets and codes.\\n\\n\\nTopics to be covered in the Workshop\\n\\n\\n\\nState of Finetuning (Talk)\\nInferencing: Prompting LLMs for a task \\n\\nzero-shot\\nfew-shot\\n\\nMemory requirements (Talk)\\nFew Shot Finetuning using PEFT Techniques\\n\\nPEFT - Prompt Tuning\\nPEFT - LORA\\n\\nPerformance comparison of Prompting vs Few shot Finetuning on two domain specific datasets.\\n\\nFinancial Phrasebank\\nESG-Prospectus-Clarity-Category \\n\\nBuilding a Replication model (Talk)\\nInstruction Finetuning on Sequence to Sequence Task\\n\\nSummarization Task: SAMSum dataset.\\nQLoRa Finetuning: Train Dolly, Alpaca LLM using Llama-2 chat model\\n\\nKey Takeaways & Closing Talk\\n\\n\\n\\n\\nPrerequisites:\\n\\nLaptop with internet connection.\\nBasic knowledge of using Python in Machine Learning.\\nUnderstanding of Large Language Model.\\nFamiliarity with HuggingFace and Collab.\\n\\n\\n\\n\\nContent URLs: \\nAll notebooks and slides can be download from GitHub link here.\\n\\n\\n\\nSpeaker Info:\\nI am an applied data scientist and research professional with 10+ years of relevant experience in solving problems leveraging advanced analytics, machine learning and deep learning techniques. I started my career as a Scientific Officer in a central government research organization (Bhabha Atomic Research Center) and worked on variety of domains such as conversational speech, satellite imagery and texts. Currently, I am working as a Director, Data Scientist with Fidelity investment for last 4 years working on language models (NLP) and Graphs.\\nAs part of my work, I have used python throughout my career for solving data science problems as well as for pursuing research. I have published several academic and applied research papers and participated in multiple conferences over years. In past, I had trained professionals in machine learning and had been guest lecturer at BITS, Pilani, WILP program for Machine Learning subject (MTech course).\\n\\n\\n\\nSpeaker Links:\\nBlog: https://appliedmachinelearning.wordpress.com/\\nGithub: https://github.com/abhijeet3922\\nLinkedln: https://www.linkedin.com/in/abhijeet-kumar-1aa8b0138/\\nOpen Source Contributions:\\n\\nfinbert-embedding: https://pypi.org/project/finbert-embedding/\\nclassitransformers: https://pypi.org/project/classitransformers/\\nPhraseExtraction\\n\\n\\n\\n', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.7977188354084902)], metadata={'1e264a40-fe2f-4c0f-954b-32427f471b0a': {'Section': 'Data Science, AI & ML', 'Type': 'Workshops', 'Target Audience': 'Beginner', 'Last Updated': '14 Sep, 2023', 'title': 'Mastering Retrieval Augmented Generation (RAG) with LlamaIndex and LLMs', 'speaker': 'ravi theja (~ravi1)'}, '4c88a110-f1a8-4581-b06a-6934b9009d20': {'Section': 'Data Science, AI & ML', 'Type': 'Workshops', 'Target Audience': 'Intermediate', 'Last Updated': '22 Sep, 2023', 'title': 'Instruction Finetuning: Unlock the Power of Large Language Models', 'speaker': 'Abhijeet Kumar (~abhijeet3922)'}})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f9639ea4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'response'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m eval_result \u001b[38;5;241m=\u001b[39m \u001b[43mrelevancy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_nodes\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m eval_result\n",
      "File \u001b[0;32m~/jjmachan/llamaindex/llamaindex/llama_index/evaluation/base.py:80\u001b[0m, in \u001b[0;36mBaseEvaluator.evaluate_response\u001b[0;34m(self, query, response, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_response\u001b[39m(\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     71\u001b[0m     query: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     72\u001b[0m     response: Optional[Response] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m     74\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m EvaluationResult:\n\u001b[1;32m     75\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run evaluation with query string and generated Response object.\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03m    Subclasses can override this method to provide custom evaluation logic and\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m    take in additional arguments.\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maevaluate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/llamaindex/lib/python3.10/site-packages/nest_asyncio.py:35\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     33\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/llamaindex/lib/python3.10/site-packages/nest_asyncio.py:90\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent loop stopped before Future completed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/asyncio/futures.py:201\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_tb)\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/asyncio/tasks.py:232\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    230\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    234\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "File \u001b[0;32m~/jjmachan/llamaindex/llamaindex/llama_index/evaluation/base.py:98\u001b[0m, in \u001b[0;36mBaseEvaluator.aevaluate_response\u001b[0;34m(self, query, response, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m contexts: Optional[Sequence[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     response_str \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\n\u001b[1;32m     99\u001b[0m     contexts \u001b[38;5;241m=\u001b[39m [node\u001b[38;5;241m.\u001b[39mget_content() \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39msource_nodes]\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maevaluate(\n\u001b[1;32m    102\u001b[0m     query\u001b[38;5;241m=\u001b[39mquery, response\u001b[38;5;241m=\u001b[39mresponse_str, contexts\u001b[38;5;241m=\u001b[39mcontexts, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    103\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'response'"
     ]
    }
   ],
   "source": [
    "eval_result = relevancy.evaluate_response(\n",
    "    query=q, response=r.response, contexts=[c.text for c in r.source_nodes]\n",
    ")\n",
    "eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513bab31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
