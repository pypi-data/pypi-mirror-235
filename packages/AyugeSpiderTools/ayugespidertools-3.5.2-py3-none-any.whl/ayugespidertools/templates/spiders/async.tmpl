import aiohttp
from scrapy.http import Request
from $project_name.settings import logger
from scrapy.http.response.text import TextResponse
from ayugespidertools.spiders import AyuSpider

"""
########################################################################################################################
# collection_website: $domain - 采集的目标站点介绍
# collection_content: 采集内容介绍
# create_time: xxxx-xx-xx
# explain: async 协程在 spider 中的写法示例
# demand_code_prefix = ""
########################################################################################################################
"""


class $classname(AyuSpider):
    name = "$name"
    allowed_domains = ["$domain"]
    start_urls = ["http://$domain/"]
    custom_settings = {
        "TWISTED_REACTOR": "twisted.internet.asyncioreactor.AsyncioSelectorReactor",
    }

    async def parse(self, response):
        self.slog.info("starting ...")
        async with aiohttp.ClientSession() as session:
            async with session.get("https://myip.ipip.net") as additional_response:
                additional_data = await additional_response.text()
                self.slog.debug(f"parse 响应内容: {additional_data}")
                yield Request(
                    url="https://myip.ipip.net",
                    callback=self.parse_first,
                    dont_filter=True,
                )

    async def parse_first(self, response: TextResponse):
        self.slog.debug(f"parse_first 响应内容: {response.text}")
