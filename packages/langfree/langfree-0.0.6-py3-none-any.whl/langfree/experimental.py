# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/03_experimental.ipynb.

# %% auto 0
__all__ = ['LLMRecord', 'LLMDataset']

# %% ../nbs/03_experimental.ipynb 2
from typing import List, Iterable, Union
from collections import Counter
from pathlib import Path
import pickle

import pandas as pd
from pydantic import BaseModel
import langsmith
from fastcore.foundation import first, L
from fastcore.test import test_eq
from .runs import (get_runs_by_commit, get_output, get_input, 
                           get_params, get_functions,
                          get_feedback, take)
from .transform import RunData
from langsmith import Client

# %% ../nbs/03_experimental.ipynb 3
class LLMRecord(BaseModel):
    "A parsed run from LangSmith, focused on the `ChatOpenAI` run type."
    child_run_id:str
    parent_run_id:str
    child_run:RunData
    llm_input:str
    llm_output: str
    url: str
    total_tokens:Union[int, None]
    prompt_tokens:Union[int, None]
    completion_tokens:Union[int, None]
    feedback: Union[List,None] = None
    feedback_keys: Union[List,None] = None
    tags: Union[List,None] = []
    start_dt: Union[str, None] = None
    parent_url: Union[str,None] = None
    parent_id: Union[str,None] = None
    function_defs: Union[List,None] = None
    param_model_name: Union[str,None]= None
    param_n: Union[int, None] = None
    param_top_p: Union[int, None] = None
    param_temp: Union[int, None] = None
    param_presence_penalty: Union[int, None] = None
    param_freq_penalty: Union[int, None] = None
    warnings: List[str] = []
    
    @classmethod
    def collate(cls, run:langsmith.schemas.Run):
        "Collate information About A Run into a `LLMRecord`."
        client = Client()
        warnings = []
        if run.execution_order != 1: # this is a child run, get the parent
            run = client.read_run(run.parent_run_id)
            
        _cruns = client.read_run(run_id=run.id, load_child_runs=True).child_runs
        crun = None
        if _cruns:
            if _cruns[-1].name != 'ChatOpenAI': 
                warnings.append('Last Step Not ChatOpenAI')
            crun = [c for c in _cruns if c.name == 'ChatOpenAI'][-1]
    
        if crun:
            _input, _output = get_input(crun), get_output(crun)
                
            if 'Agent stopped due to max iterations' in _input: warnings.append('Max Iterations')
            if _output.strip() == '': warnings.append('No Output')
            
            params = get_params(crun)
            _feedback = get_feedback(run) # you must get feedback from the root
            
            return cls(child_run_id=str(crun.id),
                       parent_run_id=str(run.id),
                       child_run=RunData.from_run_id(str(crun.id)),
                       llm_input=_input,
                       llm_output=_output,
                       url=crun.url,
                       total_tokens=crun.total_tokens,
                       prompt_tokens=crun.prompt_tokens,
                       completion_tokens=crun.completion_tokens,
                       feedback=_feedback, 
                       feedback_keys=list(L(_feedback).attrgot('key').filter()),
                       tags=run.tags,
                       start_dt=run.start_time.strftime('%m/%d/%Y'),
                       parent_url=run.url if run else None,
                       parent_id=str(run.id) if run else None,
                       function_defs=get_functions(crun),
                       warnings=warnings,
                       **params)

# %% ../nbs/03_experimental.ipynb 6
class LLMDataset(BaseModel):
    "A collection of `LLMRecord`."
    records: List[LLMRecord]
    tags: Counter
    dates: Counter
    
    @classmethod
    def from_commit(cls, commit_id:str):
        "Create a `LLMDataset` from a commit id"
        _runs = get_runs_by_commit(commit_id=commit_id)
        return cls.from_runs(_runs)
    
    @classmethod
    def from_runs(cls, runs:List[langsmith.schemas.Run]):
        "Load LLMDataset from runs."
        tag_counter=Counter()
        date_counter=Counter()
        records=[LLMRecord.collate(r) for r in runs]
        for rec in records:
            if rec.tags: tag_counter.update(rec.tags)
            if rec.start_dt: date_counter.update([rec.start_dt])
        return cls(records=records, tags=tag_counter, dates=date_counter)
    
    def __len__(self):
        return len(self.records)
    
    def save(self, path:str):
        "Save data to disk."
        dest_path = Path(path)
        if not dest_path.parent.exists(): dest_path.parent.mkdir(exist_ok=True)
        with open(dest_path, 'wb') as f:
            pickle.dump(self, f)
            return dest_path
        
    def __iter__(self):
        for r in self.records: yield r
    
    @classmethod
    def load(cls, path:str):
        "Load data from disk."
        src_path = Path(path)
        with open(src_path, 'rb') as f:
            obj = pickle.load(f)
            if isinstance(obj, cls):
                return obj
            else:
                raise TypeError(f"The loaded object is not of type {cls.__name__}")
                
    def to_pandas(self):
        "Convert the `LLMDataset` to a pandas.DataFrame."
        return pd.DataFrame(L(self.records).map(dict))
    
    def to_airtable_csv(self, path:str):
        "Format a csv such that it can be exported to Airtable conveniently."
        dest_path = Path(path)
        if not dest_path.parent.exists(): dest_path.parent.mkdir(exist_ok=True)
        if dest_path.suffix != '.csv': raise Exception(f"You must name your file with a csv extension, instead got {path}")
        data = deepcopy(self)
        for r in data.records:
            r.tags = ', '.join(r.tags)
            r.feedback_keys = ', '.join(r.feedback_keys)
            r.warnings = ', '.join(r.warnings)
        df = pd.DataFrame(L(data.records).map(dict))
        df.to_csv(dest_path)
        return dest_path
                
    def __repr__(self):
        tags = '\n'.join([f'- {x} {y}' for x,y in self.tags.most_common(5)])
        dates = '\n'.join([f'- {x} {y}' for x,y in self.dates.most_common(5)])
        return f'LLMDataset with {len(self)} records.\n\nDates:\n{dates}\n\n5 Most common tags:\n{tags}'
