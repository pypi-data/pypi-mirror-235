import torch
from enot.pruning.calibrate import calibrate_model_for_pruning as calibrate_model_for_pruning
from enot.pruning.label_selector import ChannelsSelectorConstraint as ChannelsSelectorConstraint, GlobalPruningLabelSelectorByChannels as GlobalPruningLabelSelectorByChannels, OptimalPruningLabelSelector as OptimalPruningLabelSelector, PruningLabelSelector as PruningLabelSelector, UniformPruningLabelSelector as UniformPruningLabelSelector
from enot.pruning.prune import prune_model as prune_model
from enot.utils.batch_norm import tune_bn_stats as tune_bn_stats
from enot.utils.common import Number as Number
from enot.utils.dataloader2model import DataLoaderSampleToModelInputs as DataLoaderSampleToModelInputs, DataLoaderSampleToNSamples as DataLoaderSampleToNSamples, default_sample_to_model_inputs as default_sample_to_model_inputs, default_sample_to_n_samples as default_sample_to_n_samples
from torch.utils.data import DataLoader as DataLoader
from typing import Any, Callable, Optional

def calibrate_and_prune_model(label_selector: PruningLabelSelector, model: torch.nn.Module, dataloader: DataLoader, loss_function: Callable[[Any, Any], torch.Tensor], finetune_bn: bool = ..., calibration_steps: Optional[int] = ..., calibration_epochs: int = ..., sample_to_n_samples: DataLoaderSampleToNSamples = ..., sample_to_model_inputs: DataLoaderSampleToModelInputs = ..., show_tqdm: bool = ..., entry_point: str = ...) -> torch.nn.Module: ...
def calibrate_and_prune_model_equal(model: torch.nn.Module, dataloader: DataLoader, loss_function: Callable[[Any, Any], torch.Tensor], pruning_ratio: Number = ..., finetune_bn: bool = ..., calibration_steps: Optional[int] = ..., calibration_epochs: int = ..., sample_to_n_samples: DataLoaderSampleToNSamples = ..., sample_to_model_inputs: DataLoaderSampleToModelInputs = ..., show_tqdm: bool = ..., entry_point: str = ...) -> torch.nn.Module: ...
def calibrate_and_prune_model_optimal(model: torch.nn.Module, dataloader: DataLoader, loss_function: Callable[[Any, Any], torch.Tensor], latency_calculation_function: Callable[[torch.nn.Module], float], target_latency: Number, finetune_bn: bool = ..., calibration_steps: Optional[int] = ..., calibration_epochs: int = ..., sample_to_n_samples: DataLoaderSampleToNSamples = ..., sample_to_model_inputs: DataLoaderSampleToModelInputs = ..., show_tqdm: bool = ..., channels_selection_constraint: Optional[ChannelsSelectorConstraint] = ..., n_search_steps: int = ..., entry_point: str = ..., **kwargs) -> torch.nn.Module: ...
def calibrate_and_prune_model_global_wrt_metric_drop(model: torch.nn.Module, dataloader: DataLoader, loss_function: Callable[[Any, Any], torch.Tensor], validation_function: Callable[[torch.nn.Module], float], maximal_acceptable_metric_drop: Number, minimal_channels_to_prune: int = ..., maximal_channels_to_prune: int = ..., channel_step_to_search: int = ..., finetune_bn: bool = ..., calibration_steps: Optional[int] = ..., calibration_epochs: int = ..., sample_to_n_samples: DataLoaderSampleToNSamples = ..., sample_to_model_inputs: DataLoaderSampleToModelInputs = ..., show_tqdm: bool = ..., entry_point: str = ...) -> torch.nn.Module: ...
